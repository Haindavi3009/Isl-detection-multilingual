ğŸ§  Indian Sign Language Detection & Translation (Aâ€“Z & 1â€“9 | Multilingual + Bidirectional)

ğŸš€ Overview

This project detects Indian Sign Language (ISL) gestures for Aâ€“Z alphabets and 1â€“9 numbers using Mediapipe and a Feedforward Neural Network (FNN).

Enhancements added:

1.Sign â†’ Text â†’ Voice output
2.Multilingual support (8 Indian languages)
3.Text â†’ Sign conversion for single letters and numbers
Note: Only individual letters and digits are supported; full words or sentences are not recognized.
**Note:** All output screenshots for this project are provided in the `output_screenshots` folder.
____________________________________________________________________________________________________________________________
âœ¨ Key Features

ğŸ–ï¸ Detects ISL alphabets (Aâ€“Z) and numbers (1â€“9) in real-time using webcam
ğŸ”¤ Converts detected gestures to text
ğŸ”Š Generates voice output in selected language
ğŸŒ Supports 8 Indian languages: English, Hindi, Telugu, Malayalam, Tamil, Kannada, Bengali, Marathi
ğŸ” Text â†’ Sign conversion (letters and digits only)
ğŸ¥ Real-time detection with Mediapipe and OpenCV
ğŸ§  Built using Feedforward Neural Network (FNN) for classification
_______________________________________________________________________________________________________________________________
ğŸŒ Supported Languages

The system supports both sign-to-text/voice and text-to-sign for the following 8 Indian languages:

English
Hindi
Telugu
Malayalam
Tamil
Kannada
Bengali
Marathi
_______________________________________________________________________________________________________________________________
ğŸ—ï¸ Project Structure

ISL_Multilingual_Translator/
â”‚
â”œâ”€â”€ README.md                     
â”œâ”€â”€ isl_detection.py               â†’ Detect ISL alphabets/numbers (Sign â†’ Text/Voice)
â”œâ”€â”€ text_to_sign.py                â†’ Convert single letters/numbers to ISL gestures
â”œâ”€â”€ dataset_keypoint_generation.py â†’ Convert dataset images to hand landmarks
â”œâ”€â”€ ISL_classifier.ipynb           â†’ Train FNN model
â”œâ”€â”€ model.h5                       â†’ Trained classifier model
â”œâ”€â”€ keypoint.csv                   â†’ Hand landmark dataset
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ translator.py              â†’ Multilingual translation
â”‚   â””â”€â”€ tts_engine.py              â†’ Text-to-speech
â”‚
â””â”€â”€ requirements.txt               
_______________________________________________________________________________________________________________________________

âš™ï¸ Installation

Ensure Python 3.6+ is installed, then install dependencies:
pip install mediapipe opencv-python numpy tensorflow googletrans==4.0.0-rc1 gTTS playsound

(Optional: use virtual environment)

python -m venv venv
source venv/bin/activate     # Linux/macOS
venv\Scripts\activate        # Windows
_______________________________________________________________________________________________________________________________
â–¶ï¸ Usage

Sign â†’ Text + Voice
python isl_detection.py


1.Open webcam
2.Show Aâ€“Z or 1â€“9 gestures
3.Recognized letter/number is displayed and spoken
4.Press â€˜qâ€™ to exit

Text â†’ Sign
python text_to_sign.py


Enter a single letter or number
Corresponding ISL gesture is displayed
_______________________________________________________________________________________________________________________________


ğŸ§© How It Works

1.Mediapipe detects 21 hand landmarks per frame.
2.Landmarks passed to Feedforward Neural Network (FNN) trained on ISL alphabets & numbers.
3.Predicted class (letter or number) displayed as text.
4.Text translated to selected language using Google Translate.
5.Voice generated via gTTS.
6.Text â†’ Sign shows ISL gesture for entered letter or number.
_______________________________________________________________________________________________________________________________
ğŸ§± Model Details

1.Model: Feedforward Neural Network (FNN)
2.Input: 42 hand keypoints (x, y coordinates)
3.Output: 36 classes (Aâ€“Z + 1â€“9)
4.Frameworks: TensorFlow + Mediapipe
_______________________________________________________________________________________________________________________________
ğŸš§ Future Improvements

1.Support for full words/sentences
2.Add more gesture variations for numbers/letters
3.Develop mobile/web app
4.GUI for easier interaction
_______________________________________________________________________________________________________________________________
ğŸ‘©â€ğŸ’» Author

Sira Haindavi
GitHub: https://github.com/<your-username>

Email:haindavisira@gmail.com