# ğŸ§ Indian Sign Language Detection & Translation (Aâ€“Z & 1â€“9 | Multilingual + Bidirectional)

## ğŸš€Overview
This project detects Indian Sign Language (ISL) gestures for **Aâ€“Z alphabets** and **1â€“9 numbers** using **Mediapipe** and a **Feedforward Neural Network (FNN)**.

**Enhancements added:**
- Sign â†’ Text â†’ Voice output
- Multilingual support (8 Indian languages)
- Text â†’ Sign conversion for single letters and numbers

> **Note:** Only individual letters and digits are supported; full words or sentences are not recognized.  
> **All output screenshots are in the `output_screenshots` folder.**

---

##âœ¨ Key Features
- ğŸ–ï¸Detects ISL alphabets (Aâ€“Z) and numbers (1â€“9) in real-time using webcam
- ğŸ”¤Converts detected gestures to text
- ğŸ”ŠGenerates voice output in selected language
- ğŸŒSupports 8 Indian languages: English, Hindi, Telugu, Malayalam, Tamil, Kannada, Bengali, Marathi
- ğŸ”Text â†’ Sign conversion (letters and digits only)
- ğŸ¥Real-time detection with Mediapipe and OpenCV
- ğŸ§ Built using Feedforward Neural Network (FNN) for classification

-----
**ğŸŒ Supported Languages**
- The system supports both Sign-to-Text/Voice and Text-to-Sign for the following languages:
- English
- Hindi
- Telugu
- Malayalam
- Tamil
- Kannada
- Bengali
- Marathi
---

##ğŸ—ï¸ Project Structure
```bash
ISL_Multilingual_Translator/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ isl_detection.py               â†’ Detect ISL alphabets/numbers (Sign â†’ Text/Voice)
â”œâ”€â”€ text_to_sign.py                â†’ Convert single letters/numbers to ISL gestures
â”œâ”€â”€ dataset_keypoint_generation.py â†’ Convert dataset images to hand landmarks
â”œâ”€â”€ ISL_classifier.ipynb           â†’ Train FNN model
â”œâ”€â”€ model.h5                       â†’ Trained classifier model
â”œâ”€â”€ keypoint.csv                   â†’ Hand landmark dataset
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ translator.py              â†’ Multilingual translation
â”‚   â””â”€â”€ tts_engine.py              â†’ Text-to-speech
â”‚
â””â”€â”€ requirements.txt
```
---

## âš™ï¸Installation

1. Ensure **Python 3.6+** is installed.  
2. Install dependencies:

```bash
pip install mediapipe opencv-python numpy tensorflow googletrans==4.0.0-rc1 gTTS playsound
```
3.(Optional) Use a virtual environment:

```bash
python -m venv venv
# Linux/macOS
source venv/bin/activate
# Windows
venv\Scripts\activate
```
----
â–¶ï¸Usage

Sign â†’ Text + Voice

```bash
python isl_detection.py
```
**Steps:**
1. Open webcam
2. Show Aâ€“Z or 1â€“9 gestures
3. Recognized letter/number is displayed and spoken
4. Press `q` to exit

Text â†’ Sign
```bash
python text_to_sign.py
```

**Steps:**
- Enter a single letter or number
- Corresponding ISL gesture is displayed
-----

**ğŸ§©How It Works:**
1. Mediapipe detects 21 hand landmarks per frame.
2. Landmarks are passed to the FNN trained on ISL alphabets & numbers.
3. Predicted class (letter or number) is displayed as text.
4. Text is translated to the selected language using Google Translate.
5. Voice is generated via gTTS.
6. Text â†’ Sign shows ISL gesture for the entered letter or number.

--------
**ğŸ§±Model Details:**
- Model: Feedforward Neural Network (FNN)
- Input: 42 hand keypoints (`x`, `y` coordinates)
- Output: 36 classes (Aâ€“Z + 1â€“9)
- Frameworks: TensorFlow + Mediapipe
--------
**â–¶ï¸Output Screenshots**
- All screenshots are in the output_screenshots folder.
- Replace screenshot1.png, etc. with your actual filenames.
------
**ğŸš§Future Improvements:**
- Support for full words/sentences
- Add more gesture variations for numbers/letters
- Develop mobile/web app
- GUI for easier interaction
-----
**ğŸ‘©â€ğŸ’»Author**
- Sira Haindavi
- GitHub: https://github.com/Haindavi3009
- Email: haindavisira@gmail.com
----
